{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "download_path = \"./input.csv\"\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"abhilashjash/covid-19-simulated-dataset-by-abhilash-jash\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "data_csv_location = download_path\n",
    "target_col = \"Is_Covid_True\""
   ],
   "id": "22795182f8c8f6ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = pd.read_csv(data_csv_location)\n",
    "\n",
    "# Display the first 2 rows of the dataset to get a quick look at the data\n",
    "data.head(2)\n",
    "\n",
    "# Generate summary statistics for numerical columns (count, mean, std, min, quartiles, max)\n",
    "data.describe()\n",
    "\n",
    "# Print concise information about the DataFrame: column names, non-null counts, and data types\n",
    "data.info()\n",
    "\n",
    "# Count the number of missing (NaN) values in each column\n",
    "data.isnull().sum()\n",
    "\n",
    "# Display the list of all column names in the dataset\n",
    "data.columns\n",
    "data"
   ],
   "id": "67231f7833b09924"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data.dropna(inplace=True)\n",
    "data = data.replace(False, 0)\n",
    "data = data.replace(True, 1)\n",
    "data = data.drop([\"Patient_ID\", \"Gender\", \"Name\"], axis=1)\n",
    "\n",
    "# Display the first 2 rows of the dataset to get a quick look at the data\n",
    "data.head(2)\n",
    "\n",
    "# Generate summary statistics for numerical columns (count, mean, std, min, quartiles, max)\n",
    "data.describe()\n",
    "\n",
    "# Print concise information about the DataFrame: column names, non-null counts, and data types\n",
    "data.info()"
   ],
   "id": "2b13180a6aa4dc01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Count the number of missing (NaN) values in each column\n",
    "data.isnull().sum()\n",
    "\n",
    "# Display the list of all column names in the dataset\n",
    "data"
   ],
   "id": "d95e53ad4e92de23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data.isnull().sum()",
   "id": "41083d6eff0c099a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# covid positive by blood pressure\n",
    "\n",
    "bp_data = data[[\"Blood_Pressure\", \"Is_Covid_True\"]]\n",
    "bp_data.sort_values(by=[\"Blood_Pressure\"], ascending=False, inplace=True)\n",
    "bp_data"
   ],
   "id": "272b4f08fc33c58f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Define blood pressure bins and labels\n",
    "min_blood_pressure = 80\n",
    "max_blood_pressure = 180\n",
    "step = 10\n",
    "blood_pressure_ranges = range(min_blood_pressure, max_blood_pressure + step, step)\n",
    "blood_pressure_labels = [f'{i}-{i+step}' for i in blood_pressure_ranges[:-1]]\n",
    "\n",
    "# Bin the data\n",
    "bp_data['bp_range'] = pd.cut(\n",
    "    bp_data['Blood_Pressure'],\n",
    "    bins=blood_pressure_ranges,\n",
    "    labels=blood_pressure_labels,\n",
    "    right=False\n",
    ")\n",
    "\n",
    "# Count total, positive, and negative entries\n",
    "total_counts = bp_data['bp_range'].value_counts().sort_index()\n",
    "positive_counts = bp_data[bp_data['Is_Covid_True'] == 1]['bp_range'].value_counts().sort_index()\n",
    "negative_counts = total_counts - positive_counts\n",
    "\n",
    "# Reindex to include all bins\n",
    "total_counts = total_counts.reindex(blood_pressure_labels, fill_value=0)\n",
    "positive_counts = positive_counts.reindex(blood_pressure_labels, fill_value=0)\n",
    "negative_counts = negative_counts.reindex(blood_pressure_labels, fill_value=0)\n",
    "\n",
    "# Avoid division by zero (e.g., empty bins)\n",
    "positive_percent = (positive_counts / total_counts).fillna(0)\n",
    "negative_percent = (negative_counts / total_counts).fillna(0)\n",
    "\n",
    "# Plot 100% stacked bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(blood_pressure_labels, negative_percent, bottom=positive_percent, label='COVID Negative', color='red')\n",
    "plt.bar(blood_pressure_labels, positive_percent, label='COVID Positive', color='green')\n",
    "\n",
    "\n",
    "plt.title(\"Percentage of COVID-19 Cases by Blood Pressure Range\")\n",
    "plt.xlabel(\"Blood Pressure Range\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# blood pressure isn't a useful metric\n",
    "print(positive_percent) # 78.xx% for all BP ranges\n"
   ],
   "id": "714d0756ee0614d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json, math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "    confusion_matrix, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Helper to make JSON-safe\n",
    "def to_py(o):\n",
    "    if isinstance(o, np.generic):\n",
    "        return o.item()\n",
    "    if isinstance(o, np.ndarray):\n",
    "        return o.tolist()\n",
    "    if isinstance(o, dict):\n",
    "        return {str(k): to_py(v) for k, v in o.items()}\n",
    "    if isinstance(o, (list, tuple)):\n",
    "        return [to_py(v) for v in o]\n",
    "    return o\n",
    "\n",
    "# 1. Load data\n",
    "df = data\n",
    "\n",
    "print(df[target_col])\n",
    "\n",
    "y = df[target_col].astype(int).values\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# Split categorical vs numeric\n",
    "categorical_cols, numeric_cols = [], []\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == \"object\":\n",
    "        categorical_cols.append(c)\n",
    "    elif pd.api.types.is_integer_dtype(X[c]):\n",
    "        (categorical_cols if X[c].nunique() <= 10 else numeric_cols).append(c)\n",
    "    else:\n",
    "        numeric_cols.append(c)\n",
    "\n",
    "# 2. Split train/test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Preprocessing\n",
    "numeric_transformer = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_cols),\n",
    "    (\"cat\", categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# 4. Decision Tree with hyperparameter search\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"dt\", dt)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"dt__max_depth\": [3, 4, 5, 6, None],\n",
    "    \"dt__min_samples_leaf\": [1, 2, 5, 10]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe, param_grid, cv=cv,\n",
    "    scoring=\"f1\", n_jobs=-1\n",
    ")\n",
    "grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "best_pipe = grid.best_estimator_\n",
    "best_params = grid.best_params_\n",
    "\n",
    "# 5. Choose threshold (favor recall on val set)\n",
    "val_proba = best_pipe.predict_proba(X_trainval)[:, 1]\n",
    "prec, rec, thr = precision_recall_curve(y_trainval, val_proba)\n",
    "f1s = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
    "mask = rec >= 0.85\n",
    "if mask.any():\n",
    "    idx = np.nanargmax(f1s[mask])\n",
    "    chosen_threshold = thr[max(0, np.where(mask)[0][idx] - 1)]\n",
    "else:\n",
    "    chosen_threshold = thr[np.nanargmax(f1s)] if len(thr) > 0 else 0.5\n",
    "chosen_threshold = float(chosen_threshold)\n",
    "\n",
    "# 6. Evaluate on test\n",
    "test_proba = best_pipe.predict_proba(X_test)[:, 1]\n",
    "test_pred = (test_proba >= chosen_threshold).astype(int)\n",
    "\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, test_proba)),\n",
    "    \"pr_auc\": float(average_precision_score(y_test, test_proba)),\n",
    "    \"precision\": float(precision_score(y_test, test_pred)),\n",
    "    \"recall\": float(recall_score(y_test, test_pred)),\n",
    "    \"f1\": float(f1_score(y_test, test_pred))\n",
    "}\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n",
    "metrics[\"specificity\"] = float(tn / (tn + fp + 1e-12))\n",
    "metrics[\"confusion_matrix\"] = {\"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)}\n",
    "\n",
    "# 7. Export preprocessing manifest\n",
    "preprocessor.fit(X_trainval)\n",
    "\n",
    "# Handle numeric imputation values and ranges safely\n",
    "if numeric_cols:\n",
    "    num_imputer = preprocessor.named_transformers_[\"num\"].named_steps[\"imputer\"]\n",
    "    num_impute_values = {\n",
    "        c: float(v)\n",
    "        for c, v in zip(numeric_cols, num_imputer.statistics_.tolist())\n",
    "    }\n",
    "    num_ranges = {\n",
    "        c: {\"min\": float(X_trainval[c].min()), \"max\": float(X_trainval[c].max())}\n",
    "        for c in numeric_cols\n",
    "    }\n",
    "else:\n",
    "    num_impute_values = {}\n",
    "    num_ranges = {}\n",
    "\n",
    "onehot = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_vocabs = {}\n",
    "for c, cats in zip(categorical_cols, onehot.categories_):\n",
    "    cat_vocabs[c] = [None if (isinstance(v, float) and math.isnan(v)) else v for v in cats.tolist()]\n",
    "\n",
    "final_feature_order = []\n",
    "for col in numeric_cols:\n",
    "    final_feature_order.append({\"source\": col, \"kind\": \"numeric\"})\n",
    "for col, cats in cat_vocabs.items():\n",
    "    for cat in cats:\n",
    "        final_feature_order.append({\"source\": col, \"kind\": \"onehot\", \"category\": cat})\n",
    "\n",
    "preproc_manifest = {\n",
    "    \"numeric\": numeric_cols,\n",
    "    \"categorical\": categorical_cols,\n",
    "    \"numeric_imputation\": num_impute_values,\n",
    "    \"numeric_ranges_train\": num_ranges,\n",
    "    \"categorical_vocabulary\": cat_vocabs,\n",
    "    \"final_feature_order\": final_feature_order,\n",
    "    \"preproc_version\": \"v1\",\n",
    "    \"trained_on\": datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "}\n",
    "\n",
    "\n",
    "# 8. Export Decision Tree structure\n",
    "def export_tree(tree_estimator):\n",
    "    tree = tree_estimator.tree_\n",
    "    nodes = []\n",
    "    for i in range(tree.node_count):\n",
    "        nodes.append({\n",
    "            \"feature_index\": int(tree.feature[i]),\n",
    "            \"threshold\": float(tree.threshold[i]),\n",
    "            \"left\": int(tree.children_left[i]),\n",
    "            \"right\": int(tree.children_right[i]),\n",
    "            \"value\": [float(x) for x in tree.value[i][0].tolist()],\n",
    "            \"is_leaf\": bool(tree.children_left[i] == -1 and tree.children_right[i] == -1),\n",
    "        })\n",
    "    return {\"nodes\": nodes}\n",
    "\n",
    "dt_est = best_pipe.named_steps[\"dt\"]\n",
    "dt_export = {\n",
    "    \"params\": best_params,\n",
    "    \"threshold\": chosen_threshold,\n",
    "    \"metrics\": metrics,\n",
    "    \"model_version\": \"v1\",\n",
    "    \"trained_on\": datetime.utcnow().strftime(\"%Y-%m-%d\"),\n",
    "    \"tree\": export_tree(dt_est)\n",
    "}\n",
    "\n",
    "# 9. Model Card\n",
    "model_card = f\"\"\"# Heart Disease Decision Tree Model Card\n",
    "\n",
    "**Model version:** v1  \n",
    "**Training date:** {datetime.utcnow().strftime(\"%Y-%m-%d\")}  \n",
    "\n",
    "### Best Params\n",
    "{best_params}\n",
    "\n",
    "### Metrics (Test Set)\n",
    "{json.dumps(metrics, indent=2)}\n",
    "\n",
    "### Notes\n",
    "Educational demo only — not medical advice.\n",
    "\"\"\"\n",
    "\n",
    "# 10. Golden Examples\n",
    "golden = []\n",
    "for i in range(min(10, len(X_test))):\n",
    "    row = X_test.iloc[i].to_dict()\n",
    "    golden.append({\n",
    "        \"input\": to_py(row),\n",
    "        \"pred_proba_high\": float(test_proba[i]),\n",
    "        \"label\": int(test_pred[i]),\n",
    "        \"true\": int(y_test[i])\n",
    "    })\n",
    "\n",
    "# 11. Save artifacts\n",
    "with open(\"preproc_v1.json\",\"w\") as f: json.dump(to_py(preproc_manifest),f,indent=2)\n",
    "with open(\"dt_model_v1.json\",\"w\") as f: json.dump(to_py(dt_export),f,indent=2)\n",
    "with open(\"model_card_v1.md\",\"w\") as f: f.write(model_card)\n",
    "with open(\"golden_examples_v1.json\",\"w\") as f: json.dump(to_py(golden),f,indent=2)\n",
    "\n",
    "print(\"Artifacts written: preproc_v1.json, dt_model_v1.json, model_card_v1.md, golden_examples_v1.json\")\n"
   ],
   "id": "ac0a71bbe25d7734"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTreePredictor:\n",
    "    def __init__(self, preproc_path=\"preproc_v1.json\", model_path=\"dt_model_v1.json\"):\n",
    "        \"\"\"Initialize the predictor with preprocessing and model configs\"\"\"\n",
    "        with open(preproc_path, 'r') as f:\n",
    "            self.preproc = json.load(f)\n",
    "        with open(model_path, 'r') as f:\n",
    "            self.model = json.load(f)\n",
    "        \n",
    "        self.tree = self.model['tree']['nodes']\n",
    "        self.threshold = self.model['threshold']\n",
    "        \n",
    "    def get_user_input(self):\n",
    "        \"\"\"Collect user input for all features\"\"\"\n",
    "        print(\"\\n=== Heart Disease Risk Assessment ===\")\n",
    "        print(\"Please enter the following information:\\n\")\n",
    "        \n",
    "        user_data = {}\n",
    "        \n",
    "        # Collect numeric features\n",
    "        for col in self.preproc['numeric']:\n",
    "            range_info = self.preproc['numeric_ranges_train'][col]\n",
    "            while True:\n",
    "                try:\n",
    "                    value = input(f\"{col} (typical range: {range_info['min']:.1f}-{range_info['max']:.1f}): \").strip()\n",
    "                    if value == \"\":\n",
    "                        # Use imputation value if empty\n",
    "                        user_data[col] = None\n",
    "                        print(f\"  → Using median value: {self.preproc['numeric_imputation'][col]:.1f}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        user_data[col] = float(value)\n",
    "                        break\n",
    "                except ValueError:\n",
    "                    print(\"  Please enter a valid number or press Enter to use default\")\n",
    "        \n",
    "        # Collect categorical features\n",
    "        for col in self.preproc['categorical']:\n",
    "            vocab = self.preproc['categorical_vocabulary'][col]\n",
    "            print(f\"\\n{col} options: {', '.join(str(v) for v in vocab if v is not None)}\")\n",
    "            while True:\n",
    "                value = input(f\"{col}: \").strip()\n",
    "                if value == \"\":\n",
    "                    user_data[col] = None\n",
    "                    print(f\"  → Using most frequent value\")\n",
    "                    break\n",
    "                # Try to convert to appropriate type\n",
    "                try:\n",
    "                    if value.isdigit():\n",
    "                        value = int(value)\n",
    "                    user_data[col] = value\n",
    "                    break\n",
    "                except:\n",
    "                    user_data[col] = value\n",
    "                    break\n",
    "        \n",
    "        return user_data\n",
    "    \n",
    "    def preprocess_input(self, user_data):\n",
    "        \"\"\"Apply preprocessing to user input\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Process numeric features\n",
    "        for col in self.preproc['numeric']:\n",
    "            value = user_data.get(col)\n",
    "            if value is None:\n",
    "                # Apply imputation\n",
    "                value = self.preproc['numeric_imputation'][col]\n",
    "            features.append(value)\n",
    "        \n",
    "        # Process categorical features with one-hot encoding\n",
    "        for col in self.preproc['categorical']:\n",
    "            value = user_data.get(col)\n",
    "            vocab = self.preproc['categorical_vocabulary'][col]\n",
    "            \n",
    "            # Create one-hot encoding\n",
    "            for category in vocab:\n",
    "                if value == category:\n",
    "                    features.append(1.0)\n",
    "                else:\n",
    "                    features.append(0.0)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def trace_tree(self, features):\n",
    "        \"\"\"Trace through the decision tree and return path\"\"\"\n",
    "        path = []\n",
    "        node_idx = 0  # Start at root\n",
    "        \n",
    "        while True:\n",
    "            node = self.tree[node_idx]\n",
    "            \n",
    "            if node['is_leaf']:\n",
    "                # Reached a leaf node\n",
    "                path.append({\n",
    "                    'node': node_idx,\n",
    "                    'type': 'leaf',\n",
    "                    'values': node['value']\n",
    "                })\n",
    "                break\n",
    "            \n",
    "            # Get feature name for this split\n",
    "            feature_idx = node['feature_index']\n",
    "            feature_info = self.preproc['final_feature_order'][feature_idx]\n",
    "            \n",
    "            # Make decision\n",
    "            feature_value = features[feature_idx]\n",
    "            threshold = node['threshold']\n",
    "            \n",
    "            if feature_value <= threshold:\n",
    "                next_node = node['left']\n",
    "                direction = 'left'\n",
    "                condition = f\"<= {threshold:.3f}\"\n",
    "            else:\n",
    "                next_node = node['right']\n",
    "                direction = 'right'\n",
    "                condition = f\"> {threshold:.3f}\"\n",
    "            \n",
    "            path.append({\n",
    "                'node': node_idx,\n",
    "                'type': 'decision',\n",
    "                'feature': feature_info,\n",
    "                'feature_value': feature_value,\n",
    "                'threshold': threshold,\n",
    "                'direction': direction,\n",
    "                'condition': condition\n",
    "            })\n",
    "            \n",
    "            node_idx = next_node\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    def predict(self, features):\n",
    "        \"\"\"Make prediction using the decision tree\"\"\"\n",
    "        # Trace to leaf node\n",
    "        node_idx = 0\n",
    "        while not self.tree[node_idx]['is_leaf']:\n",
    "            node = self.tree[node_idx]\n",
    "            if features[node['feature_index']] <= node['threshold']:\n",
    "                node_idx = node['left']\n",
    "            else:\n",
    "                node_idx = node['right']\n",
    "        \n",
    "        # Get prediction from leaf node\n",
    "        leaf_values = self.tree[node_idx]['value']\n",
    "        # Convert to probability (positive class)\n",
    "        total = sum(leaf_values)\n",
    "        prob_positive = leaf_values[1] / total if total > 0 else 0\n",
    "        \n",
    "        return prob_positive\n",
    "    \n",
    "    def display_results(self, user_data, features, path, prob_positive):\n",
    "        \"\"\"Display the prediction results and decision path\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PREDICTION RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Show input summary\n",
    "        print(\"\\n📊 Input Summary:\")\n",
    "        for col, value in user_data.items():\n",
    "            if value is not None:\n",
    "                print(f\"  • {col}: {value}\")\n",
    "            else:\n",
    "                if col in self.preproc['numeric']:\n",
    "                    print(f\"  • {col}: {self.preproc['numeric_imputation'][col]:.1f} (imputed)\")\n",
    "                else:\n",
    "                    print(f\"  • {col}: (imputed)\")\n",
    "        \n",
    "        # Show decision path\n",
    "        print(\"\\n🌳 Decision Path:\")\n",
    "        for i, step in enumerate(path):\n",
    "            if step['type'] == 'decision':\n",
    "                feature = step['feature']\n",
    "                if feature['kind'] == 'numeric':\n",
    "                    feature_name = feature['source']\n",
    "                else:\n",
    "                    feature_name = f\"{feature['source']}={feature['category']}\"\n",
    "                \n",
    "                print(f\"  Step {i+1}: {feature_name} = {step['feature_value']:.3f} {step['condition']}\")\n",
    "                print(f\"          → Go {step['direction']}\")\n",
    "            else:\n",
    "                print(f\"  Step {i+1}: Reached leaf node #{step['node']}\")\n",
    "        \n",
    "        # Show prediction\n",
    "        print(\"\\n🎯 Prediction:\")\n",
    "        print(f\"  Probability of COVID-19: {prob_positive:.1%}\")\n",
    "        \n",
    "        prediction = 1 if prob_positive >= self.threshold else 0\n",
    "        risk_level = \"HIGH\" if prediction == 1 else \"LOW\"\n",
    "        \n",
    "        print(f\"  Threshold: {self.threshold:.3f}\")\n",
    "        print(f\"  Classification: {risk_level} RISK\")\n",
    "        \n",
    "        # Show model performance context\n",
    "        print(\"\\n📈 Model Performance (on test set):\")\n",
    "        metrics = self.model['metrics']\n",
    "        print(f\"  • Precision: {metrics['precision']:.1%}\")\n",
    "        print(f\"  • Recall: {metrics['recall']:.1%}\")\n",
    "        print(f\"  • F1 Score: {metrics['f1']:.1%}\")\n",
    "        \n",
    "        print(\"\\n⚠️  DISCLAIMER: This is for educational purposes only.\")\n",
    "        print(\"    Please consult healthcare professionals for medical advice.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the predictor\"\"\"\n",
    "    try:\n",
    "        # Initialize predictor\n",
    "        predictor = DecisionTreePredictor()\n",
    "        \n",
    "        while True:\n",
    "            # Get user input\n",
    "            user_data = predictor.get_user_input()\n",
    "            \n",
    "            # Preprocess input\n",
    "            features = predictor.preprocess_input(user_data)\n",
    "            \n",
    "            # Trace decision path\n",
    "            path = predictor.trace_tree(features)\n",
    "            \n",
    "            # Get prediction\n",
    "            prob_positive = predictor.predict(features)\n",
    "            \n",
    "            # Display results\n",
    "            predictor.display_results(user_data, features, path, prob_positive)\n",
    "            \n",
    "            # Ask if user wants to continue\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            again = input(\"\\nWould you like to assess another case? (yes/no): \").strip().lower()\n",
    "            if again not in ['yes', 'y']:\n",
    "                print(\"\\nThank you for using the Heart Disease Risk Assessment tool!\")\n",
    "                break\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find required files. Please ensure 'preproc_v1.json' and 'dt_model_v1.json' exist.\")\n",
    "        print(f\"Details: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "bf241eaae4b8b323"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "0\n",
   "id": "a35fd4d91bdcf3a1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
