{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:34:05.076824Z",
     "start_time": "2025-10-01T18:34:01.222371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"abhilashjash/covid-19-simulated-dataset-by-abhilash-jash\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "data_csv_location = \"covid-data.csv\"\n",
    "target_col = \"COVID-19\""
   ],
   "id": "349590f6c91e3a31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/abhilashjash/covid-19-simulated-dataset-by-abhilash-jash?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.7M/26.7M [00:01<00:00, 14.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\thecr\\.cache\\kagglehub\\datasets\\abhilashjash\\covid-19-simulated-dataset-by-abhilash-jash\\versions\\1\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "id": "5e855efb-feeb-49f6-97ae-f7dd26c69f65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:24:41.763113Z",
     "start_time": "2025-10-01T18:24:41.692784Z"
    }
   },
   "source": [
    "data = pd.read_csv(data_csv_location)\n",
    "\n",
    "# Display the first 2 rows of the dataset to get a quick look at the data\n",
    "data.head(2)\n",
    "\n",
    "# Generate summary statistics for numerical columns (count, mean, std, min, quartiles, max)\n",
    "data.describe()\n",
    "\n",
    "# Print concise information about the DataFrame: column names, non-null counts, and data types\n",
    "data.info()\n",
    "\n",
    "# Count the number of missing (NaN) values in each column\n",
    "data.isnull().sum()\n",
    "\n",
    "# Display the list of all column names in the dataset\n",
    "data.columns"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5434 entries, 0 to 5433\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype\n",
      "---  ------                --------------  -----\n",
      " 0   Breathing Problem     5434 non-null   int64\n",
      " 1   Fever                 5434 non-null   int64\n",
      " 2   Dry Cough             5434 non-null   int64\n",
      " 3   Sore throat           5434 non-null   int64\n",
      " 4   Running Nose          5434 non-null   int64\n",
      " 5   Asthma                5434 non-null   int64\n",
      " 6   Chronic Lung Disease  5434 non-null   int64\n",
      " 7   Headache              5434 non-null   int64\n",
      " 8   Heart Disease         5434 non-null   int64\n",
      " 9   Diabetes              5434 non-null   int64\n",
      " 10  Hypertension          5434 non-null   int64\n",
      " 11  Fatigue               5434 non-null   int64\n",
      " 12  Gastrointestinal      5434 non-null   int64\n",
      " 13  COVID-19              5434 non-null   int64\n",
      "dtypes: int64(14)\n",
      "memory usage: 594.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Breathing Problem', 'Fever', 'Dry Cough', 'Sore throat',\n",
       "       'Running Nose', 'Asthma', 'Chronic Lung Disease', 'Headache',\n",
       "       'Heart Disease', 'Diabetes', 'Hypertension', 'Fatigue ',\n",
       "       'Gastrointestinal ', 'COVID-19'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "4fdecaec-8f91-492a-bd68-006566b14c4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:24:41.810236Z",
     "start_time": "2025-10-01T18:24:41.794635Z"
    }
   },
   "source": [
    "data.isnull().sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Breathing Problem       0\n",
       "Fever                   0\n",
       "Dry Cough               0\n",
       "Sore throat             0\n",
       "Running Nose            0\n",
       "Asthma                  0\n",
       "Chronic Lung Disease    0\n",
       "Headache                0\n",
       "Heart Disease           0\n",
       "Diabetes                0\n",
       "Hypertension            0\n",
       "Fatigue                 0\n",
       "Gastrointestinal        0\n",
       "COVID-19                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "id": "dae82819-2274-40df-9234-cb3a6159d767",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:24:47.714985Z",
     "start_time": "2025-10-01T18:24:41.896513Z"
    }
   },
   "source": [
    "import json, math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "    confusion_matrix, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Helper to make JSON-safe\n",
    "def to_py(o):\n",
    "    if isinstance(o, np.generic):\n",
    "        return o.item()\n",
    "    if isinstance(o, np.ndarray):\n",
    "        return o.tolist()\n",
    "    if isinstance(o, dict):\n",
    "        return {str(k): to_py(v) for k, v in o.items()}\n",
    "    if isinstance(o, (list, tuple)):\n",
    "        return [to_py(v) for v in o]\n",
    "    return o\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv(data_csv_location)\n",
    "\n",
    "y = df[target_col].astype(int).values\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# Split categorical vs numeric\n",
    "categorical_cols, numeric_cols = [], []\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == \"object\":\n",
    "        categorical_cols.append(c)\n",
    "    elif pd.api.types.is_integer_dtype(X[c]):\n",
    "        (categorical_cols if X[c].nunique() <= 10 else numeric_cols).append(c)\n",
    "    else:\n",
    "        numeric_cols.append(c)\n",
    "\n",
    "# 2. Split train/test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Preprocessing\n",
    "numeric_transformer = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_cols),\n",
    "    (\"cat\", categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# 4. Decision Tree with hyperparameter search\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"dt\", dt)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"dt__max_depth\": [3, 4, 5, 6, None],\n",
    "    \"dt__min_samples_leaf\": [1, 2, 5, 10]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe, param_grid, cv=cv,\n",
    "    scoring=\"f1\", n_jobs=-1\n",
    ")\n",
    "grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "best_pipe = grid.best_estimator_\n",
    "best_params = grid.best_params_\n",
    "\n",
    "# 5. Choose threshold (favor recall on val set)\n",
    "val_proba = best_pipe.predict_proba(X_trainval)[:, 1]\n",
    "prec, rec, thr = precision_recall_curve(y_trainval, val_proba)\n",
    "f1s = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
    "mask = rec >= 0.85\n",
    "if mask.any():\n",
    "    idx = np.nanargmax(f1s[mask])\n",
    "    chosen_threshold = thr[max(0, np.where(mask)[0][idx] - 1)]\n",
    "else:\n",
    "    chosen_threshold = thr[np.nanargmax(f1s)] if len(thr) > 0 else 0.5\n",
    "chosen_threshold = float(chosen_threshold)\n",
    "\n",
    "# 6. Evaluate on test\n",
    "test_proba = best_pipe.predict_proba(X_test)[:, 1]\n",
    "test_pred = (test_proba >= chosen_threshold).astype(int)\n",
    "\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, test_proba)),\n",
    "    \"pr_auc\": float(average_precision_score(y_test, test_proba)),\n",
    "    \"precision\": float(precision_score(y_test, test_pred)),\n",
    "    \"recall\": float(recall_score(y_test, test_pred)),\n",
    "    \"f1\": float(f1_score(y_test, test_pred))\n",
    "}\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n",
    "metrics[\"specificity\"] = float(tn / (tn + fp + 1e-12))\n",
    "metrics[\"confusion_matrix\"] = {\"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)}\n",
    "\n",
    "# 7. Export preprocessing manifest\n",
    "preprocessor.fit(X_trainval)\n",
    "\n",
    "# Handle numeric imputation values and ranges safely\n",
    "if numeric_cols:\n",
    "    num_imputer = preprocessor.named_transformers_[\"num\"].named_steps[\"imputer\"]\n",
    "    num_impute_values = {\n",
    "        c: float(v)\n",
    "        for c, v in zip(numeric_cols, num_imputer.statistics_.tolist())\n",
    "    }\n",
    "    num_ranges = {\n",
    "        c: {\"min\": float(X_trainval[c].min()), \"max\": float(X_trainval[c].max())}\n",
    "        for c in numeric_cols\n",
    "    }\n",
    "else:\n",
    "    num_impute_values = {}\n",
    "    num_ranges = {}\n",
    "\n",
    "onehot = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_vocabs = {}\n",
    "for c, cats in zip(categorical_cols, onehot.categories_):\n",
    "    cat_vocabs[c] = [None if (isinstance(v, float) and math.isnan(v)) else v for v in cats.tolist()]\n",
    "\n",
    "final_feature_order = []\n",
    "for col in numeric_cols:\n",
    "    final_feature_order.append({\"source\": col, \"kind\": \"numeric\"})\n",
    "for col, cats in cat_vocabs.items():\n",
    "    for cat in cats:\n",
    "        final_feature_order.append({\"source\": col, \"kind\": \"onehot\", \"category\": cat})\n",
    "\n",
    "preproc_manifest = {\n",
    "    \"numeric\": numeric_cols,\n",
    "    \"categorical\": categorical_cols,\n",
    "    \"numeric_imputation\": num_impute_values,\n",
    "    \"numeric_ranges_train\": num_ranges,\n",
    "    \"categorical_vocabulary\": cat_vocabs,\n",
    "    \"final_feature_order\": final_feature_order,\n",
    "    \"preproc_version\": \"v1\",\n",
    "    \"trained_on\": datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "}\n",
    "\n",
    "\n",
    "# 8. Export Decision Tree structure\n",
    "def export_tree(tree_estimator):\n",
    "    tree = tree_estimator.tree_\n",
    "    nodes = []\n",
    "    for i in range(tree.node_count):\n",
    "        nodes.append({\n",
    "            \"feature_index\": int(tree.feature[i]),\n",
    "            \"threshold\": float(tree.threshold[i]),\n",
    "            \"left\": int(tree.children_left[i]),\n",
    "            \"right\": int(tree.children_right[i]),\n",
    "            \"value\": [float(x) for x in tree.value[i][0].tolist()],\n",
    "            \"is_leaf\": bool(tree.children_left[i] == -1 and tree.children_right[i] == -1),\n",
    "        })\n",
    "    return {\"nodes\": nodes}\n",
    "\n",
    "dt_est = best_pipe.named_steps[\"dt\"]\n",
    "dt_export = {\n",
    "    \"params\": best_params,\n",
    "    \"threshold\": chosen_threshold,\n",
    "    \"metrics\": metrics,\n",
    "    \"model_version\": \"v1\",\n",
    "    \"trained_on\": datetime.utcnow().strftime(\"%Y-%m-%d\"),\n",
    "    \"tree\": export_tree(dt_est)\n",
    "}\n",
    "\n",
    "# 9. Model Card\n",
    "model_card = f\"\"\"# Heart Disease Decision Tree Model Card\n",
    "\n",
    "**Model version:** v1  \n",
    "**Training date:** {datetime.utcnow().strftime(\"%Y-%m-%d\")}  \n",
    "\n",
    "### Best Params\n",
    "{best_params}\n",
    "\n",
    "### Metrics (Test Set)\n",
    "{json.dumps(metrics, indent=2)}\n",
    "\n",
    "### Notes\n",
    "Educational demo only â€” not medical advice.\n",
    "\"\"\"\n",
    "\n",
    "# 10. Golden Examples\n",
    "golden = []\n",
    "for i in range(min(10, len(X_test))):\n",
    "    row = X_test.iloc[i].to_dict()\n",
    "    golden.append({\n",
    "        \"input\": to_py(row),\n",
    "        \"pred_proba_high\": float(test_proba[i]),\n",
    "        \"label\": int(test_pred[i]),\n",
    "        \"true\": int(y_test[i])\n",
    "    })\n",
    "\n",
    "# 11. Save artifacts\n",
    "with open(\"preproc_v1.json\",\"w\") as f: json.dump(to_py(preproc_manifest),f,indent=2)\n",
    "with open(\"dt_model_v1.json\",\"w\") as f: json.dump(to_py(dt_export),f,indent=2)\n",
    "with open(\"model_card_v1.md\",\"w\") as f: f.write(model_card)\n",
    "with open(\"golden_examples_v1.json\",\"w\") as f: json.dump(to_py(golden),f,indent=2)\n",
    "\n",
    "print(\"Artifacts written: preproc_v1.json, dt_model_v1.json, model_card_v1.md, golden_examples_v1.json\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts written: preproc_v1.json, dt_model_v1.json, model_card_v1.md, golden_examples_v1.json\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "id": "c7ee4c53-5fc2-464f-a350-6ccbb7053222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:25:16.219768Z",
     "start_time": "2025-10-01T18:24:48.236753Z"
    }
   },
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTreePredictor:\n",
    "    def __init__(self, preproc_path=\"preproc_v1.json\", model_path=\"dt_model_v1.json\"):\n",
    "        \"\"\"Initialize the predictor with preprocessing and model configs\"\"\"\n",
    "        with open(preproc_path, 'r') as f:\n",
    "            self.preproc = json.load(f)\n",
    "        with open(model_path, 'r') as f:\n",
    "            self.model = json.load(f)\n",
    "        \n",
    "        self.tree = self.model['tree']['nodes']\n",
    "        self.threshold = self.model['threshold']\n",
    "        \n",
    "    def get_user_input(self):\n",
    "        \"\"\"Collect user input for all features\"\"\"\n",
    "        print(\"\\n=== Heart Disease Risk Assessment ===\")\n",
    "        print(\"Please enter the following information:\\n\")\n",
    "        \n",
    "        user_data = {}\n",
    "        \n",
    "        # Collect numeric features\n",
    "        for col in self.preproc['numeric']:\n",
    "            range_info = self.preproc['numeric_ranges_train'][col]\n",
    "            while True:\n",
    "                try:\n",
    "                    value = input(f\"{col} (typical range: {range_info['min']:.1f}-{range_info['max']:.1f}): \").strip()\n",
    "                    if value == \"\":\n",
    "                        # Use imputation value if empty\n",
    "                        user_data[col] = None\n",
    "                        print(f\"  â†’ Using median value: {self.preproc['numeric_imputation'][col]:.1f}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        user_data[col] = float(value)\n",
    "                        break\n",
    "                except ValueError:\n",
    "                    print(\"  Please enter a valid number or press Enter to use default\")\n",
    "        \n",
    "        # Collect categorical features\n",
    "        for col in self.preproc['categorical']:\n",
    "            vocab = self.preproc['categorical_vocabulary'][col]\n",
    "            print(f\"\\n{col} options: {', '.join(str(v) for v in vocab if v is not None)}\")\n",
    "            while True:\n",
    "                value = input(f\"{col}: \").strip()\n",
    "                if value == \"\":\n",
    "                    user_data[col] = None\n",
    "                    print(f\"  â†’ Using most frequent value\")\n",
    "                    break\n",
    "                # Try to convert to appropriate type\n",
    "                try:\n",
    "                    if value.isdigit():\n",
    "                        value = int(value)\n",
    "                    user_data[col] = value\n",
    "                    break\n",
    "                except:\n",
    "                    user_data[col] = value\n",
    "                    break\n",
    "        \n",
    "        return user_data\n",
    "    \n",
    "    def preprocess_input(self, user_data):\n",
    "        \"\"\"Apply preprocessing to user input\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Process numeric features\n",
    "        for col in self.preproc['numeric']:\n",
    "            value = user_data.get(col)\n",
    "            if value is None:\n",
    "                # Apply imputation\n",
    "                value = self.preproc['numeric_imputation'][col]\n",
    "            features.append(value)\n",
    "        \n",
    "        # Process categorical features with one-hot encoding\n",
    "        for col in self.preproc['categorical']:\n",
    "            value = user_data.get(col)\n",
    "            vocab = self.preproc['categorical_vocabulary'][col]\n",
    "            \n",
    "            # Create one-hot encoding\n",
    "            for category in vocab:\n",
    "                if value == category:\n",
    "                    features.append(1.0)\n",
    "                else:\n",
    "                    features.append(0.0)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def trace_tree(self, features):\n",
    "        \"\"\"Trace through the decision tree and return path\"\"\"\n",
    "        path = []\n",
    "        node_idx = 0  # Start at root\n",
    "        \n",
    "        while True:\n",
    "            node = self.tree[node_idx]\n",
    "            \n",
    "            if node['is_leaf']:\n",
    "                # Reached a leaf node\n",
    "                path.append({\n",
    "                    'node': node_idx,\n",
    "                    'type': 'leaf',\n",
    "                    'values': node['value']\n",
    "                })\n",
    "                break\n",
    "            \n",
    "            # Get feature name for this split\n",
    "            feature_idx = node['feature_index']\n",
    "            feature_info = self.preproc['final_feature_order'][feature_idx]\n",
    "            \n",
    "            # Make decision\n",
    "            feature_value = features[feature_idx]\n",
    "            threshold = node['threshold']\n",
    "            \n",
    "            if feature_value <= threshold:\n",
    "                next_node = node['left']\n",
    "                direction = 'left'\n",
    "                condition = f\"<= {threshold:.3f}\"\n",
    "            else:\n",
    "                next_node = node['right']\n",
    "                direction = 'right'\n",
    "                condition = f\"> {threshold:.3f}\"\n",
    "            \n",
    "            path.append({\n",
    "                'node': node_idx,\n",
    "                'type': 'decision',\n",
    "                'feature': feature_info,\n",
    "                'feature_value': feature_value,\n",
    "                'threshold': threshold,\n",
    "                'direction': direction,\n",
    "                'condition': condition\n",
    "            })\n",
    "            \n",
    "            node_idx = next_node\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    def predict(self, features):\n",
    "        \"\"\"Make prediction using the decision tree\"\"\"\n",
    "        # Trace to leaf node\n",
    "        node_idx = 0\n",
    "        while not self.tree[node_idx]['is_leaf']:\n",
    "            node = self.tree[node_idx]\n",
    "            if features[node['feature_index']] <= node['threshold']:\n",
    "                node_idx = node['left']\n",
    "            else:\n",
    "                node_idx = node['right']\n",
    "        \n",
    "        # Get prediction from leaf node\n",
    "        leaf_values = self.tree[node_idx]['value']\n",
    "        # Convert to probability (positive class)\n",
    "        total = sum(leaf_values)\n",
    "        prob_positive = leaf_values[1] / total if total > 0 else 0\n",
    "        \n",
    "        return prob_positive\n",
    "    \n",
    "    def display_results(self, user_data, features, path, prob_positive):\n",
    "        \"\"\"Display the prediction results and decision path\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PREDICTION RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Show input summary\n",
    "        print(\"\\nðŸ“Š Input Summary:\")\n",
    "        for col, value in user_data.items():\n",
    "            if value is not None:\n",
    "                print(f\"  â€¢ {col}: {value}\")\n",
    "            else:\n",
    "                if col in self.preproc['numeric']:\n",
    "                    print(f\"  â€¢ {col}: {self.preproc['numeric_imputation'][col]:.1f} (imputed)\")\n",
    "                else:\n",
    "                    print(f\"  â€¢ {col}: (imputed)\")\n",
    "        \n",
    "        # Show decision path\n",
    "        print(\"\\nðŸŒ³ Decision Path:\")\n",
    "        for i, step in enumerate(path):\n",
    "            if step['type'] == 'decision':\n",
    "                feature = step['feature']\n",
    "                if feature['kind'] == 'numeric':\n",
    "                    feature_name = feature['source']\n",
    "                else:\n",
    "                    feature_name = f\"{feature['source']}={feature['category']}\"\n",
    "                \n",
    "                print(f\"  Step {i+1}: {feature_name} = {step['feature_value']:.3f} {step['condition']}\")\n",
    "                print(f\"          â†’ Go {step['direction']}\")\n",
    "            else:\n",
    "                print(f\"  Step {i+1}: Reached leaf node #{step['node']}\")\n",
    "        \n",
    "        # Show prediction\n",
    "        print(\"\\nðŸŽ¯ Prediction:\")\n",
    "        print(f\"  Probability of COVID-19: {prob_positive:.1%}\")\n",
    "        \n",
    "        prediction = 1 if prob_positive >= self.threshold else 0\n",
    "        risk_level = \"HIGH\" if prediction == 1 else \"LOW\"\n",
    "        \n",
    "        print(f\"  Threshold: {self.threshold:.3f}\")\n",
    "        print(f\"  Classification: {risk_level} RISK\")\n",
    "        \n",
    "        # Show model performance context\n",
    "        print(\"\\nðŸ“ˆ Model Performance (on test set):\")\n",
    "        metrics = self.model['metrics']\n",
    "        print(f\"  â€¢ Precision: {metrics['precision']:.1%}\")\n",
    "        print(f\"  â€¢ Recall: {metrics['recall']:.1%}\")\n",
    "        print(f\"  â€¢ F1 Score: {metrics['f1']:.1%}\")\n",
    "        \n",
    "        print(\"\\nâš ï¸  DISCLAIMER: This is for educational purposes only.\")\n",
    "        print(\"    Please consult healthcare professionals for medical advice.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the predictor\"\"\"\n",
    "    try:\n",
    "        # Initialize predictor\n",
    "        predictor = DecisionTreePredictor()\n",
    "        \n",
    "        while True:\n",
    "            # Get user input\n",
    "            user_data = predictor.get_user_input()\n",
    "            \n",
    "            # Preprocess input\n",
    "            features = predictor.preprocess_input(user_data)\n",
    "            \n",
    "            # Trace decision path\n",
    "            path = predictor.trace_tree(features)\n",
    "            \n",
    "            # Get prediction\n",
    "            prob_positive = predictor.predict(features)\n",
    "            \n",
    "            # Display results\n",
    "            predictor.display_results(user_data, features, path, prob_positive)\n",
    "            \n",
    "            # Ask if user wants to continue\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            again = input(\"\\nWould you like to assess another case? (yes/no): \").strip().lower()\n",
    "            if again not in ['yes', 'y']:\n",
    "                print(\"\\nThank you for using the Heart Disease Risk Assessment tool!\")\n",
    "                break\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find required files. Please ensure 'preproc_v1.json' and 'dt_model_v1.json' exist.\")\n",
    "        print(f\"Details: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Heart Disease Risk Assessment ===\n",
      "Please enter the following information:\n",
      "\n",
      "\n",
      "Breathing Problem options: 0, 1\n",
      "\n",
      "Fever options: 0, 1\n",
      "\n",
      "Dry Cough options: 0, 1\n",
      "\n",
      "Sore throat options: 0, 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[68], line 243\u001B[0m\n\u001B[0;32m    240\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 243\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[68], line 214\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m    210\u001B[0m predictor \u001B[38;5;241m=\u001B[39m DecisionTreePredictor()\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;66;03m# Get user input\u001B[39;00m\n\u001B[1;32m--> 214\u001B[0m     user_data \u001B[38;5;241m=\u001B[39m \u001B[43mpredictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_user_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# Preprocess input\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     features \u001B[38;5;241m=\u001B[39m predictor\u001B[38;5;241m.\u001B[39mpreprocess_input(user_data)\n",
      "Cell \u001B[1;32mIn[68], line 44\u001B[0m, in \u001B[0;36mDecisionTreePredictor.get_user_input\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mcol\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m options: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mstr\u001B[39m(v)\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mv\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mvocab\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39mv\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mis\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m---> 44\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mcol\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m: \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m value \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     46\u001B[0m         user_data[col] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1280\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[1;32m-> 1282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1287\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1322\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1323\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m   1324\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1325\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "7c1abf8c-9b51-4bf6-be7b-4aad1279d3ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T18:25:16.258453800Z",
     "start_time": "2025-10-01T18:19:36.580033Z"
    }
   },
   "source": "0\n",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
